{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q1 Analysis Builder\n",
        "Creates a gold table at `data/gold/zillow/q1_analysis.parquet` with columns:\n",
        "`[Date, Region, RegionType, MedianSalePrice, MedianListingPrice, SaleToListRatio, PctSoldAboveList, PctSoldBelowList, DaysOnMarket]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6eea0657",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Q1] Input silver files located.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import polars as pl\n",
        "\n",
        "def log(msg: str) -> None:\n",
        "    print(f'[Q1] {msg}')\n",
        "\n",
        "def find_repo_root(start: Path | None = None) -> Path:\n",
        "    start = (start or Path.cwd()).resolve()\n",
        "    for p in (start, *start.parents):\n",
        "        if (p / 'ETL').is_dir() and (p / 'scripts').is_dir():\n",
        "            return p\n",
        "    return start  # fallback\n",
        "\n",
        "ROOT = find_repo_root()\n",
        "SILVER = ROOT / 'data' / 'silver' / 'zillow'\n",
        "GOLD = ROOT / 'data' / 'gold' / 'zillow'\n",
        "\n",
        "sales_path = SILVER / 'sales' / 'wide.parquet'\n",
        "listings_path = SILVER / 'for_sale_listings' / 'wide.parquet'\n",
        "dom_path = SILVER / 'days_on_market' / 'wide.parquet'\n",
        "\n",
        "for p in (sales_path, listings_path, dom_path):\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f'Missing required silver file: {p}')\n",
        "\n",
        "log('Input silver files located.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "579e94c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sales columns: ['Region ID', 'Size Rank', 'Region', 'Region Type', 'State', 'Home Type', 'Date', 'Mean Sale to List Ratio (Smoothed)', 'Median Sale to List Ratio', 'Median Sale Price', 'Median Sale Price (Smoothed) (Seasonally Adjusted)', 'Median Sale Price (Smoothed)', 'Median Sale to List Ratio (Smoothed)', '% Sold Below List', '% Sold Below List (Smoothed)', '% Sold Above List', '% Sold Above List (Smoothed)', 'Mean Sale to List Ratio', 'date', 'Region Type Name', 'Home Type Name', 'year', 'month', 'quarter']\n",
            "listings columns: ['Region ID', 'Size Rank', 'Region', 'Region Type', 'State', 'Home Type', 'Date', 'Median Listing Price', 'Median Listing Price (Smoothed)', 'New Listings', 'New Listings (Smoothed)', 'New Pending (Smoothed)', 'New Pending', 'date', 'Region Type Name', 'Home Type Name', 'year', 'month', 'quarter']\n",
            "dom columns: ['Region ID', 'Size Rank', 'Region', 'Region Type', 'State', 'Home Type', 'Date', 'Mean Listings Price Cut Amount (Smoothed)', 'Percent Listings Price Cut', 'Mean Listings Price Cut Amount', 'Percent Listings Price Cut (Smoothed)', 'Median Days on Pending (Smoothed)', 'Median Days on Pending', 'date', 'Region Type Name', 'Home Type Name', 'year', 'month', 'quarter']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'sales': [], 'listings': [], 'days_on_market': []}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspect schemas and confirm required columns exist\n",
        "sales_cols = list(pl.read_parquet(str(sales_path), n_rows=0).schema.keys())\n",
        "listings_cols = list(pl.read_parquet(str(listings_path), n_rows=0).schema.keys())\n",
        "dom_cols = list(pl.read_parquet(str(dom_path), n_rows=0).schema.keys())\n",
        "\n",
        "print('sales columns:', sales_cols)\n",
        "print('listings columns:', listings_cols)\n",
        "print('dom columns:', dom_cols)\n",
        "\n",
        "needed_sales = ['State', 'date', 'Median Sale Price', 'Median Sale to List Ratio', '% Sold Above List', '% Sold Below List']\n",
        "needed_listings = ['State', 'date', 'Median Listing Price']\n",
        "needed_dom = ['State', 'date', 'Median Days on Pending']\n",
        "\n",
        "missing = {\n",
        "    'sales': [c for c in needed_sales if c not in sales_cols],\n",
        "    'listings': [c for c in needed_listings if c not in listings_cols],\n",
        "    'days_on_market': [c for c in needed_dom if c not in dom_cols],\n",
        "}\n",
        "missing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b52c2016",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((34776, 6),\n",
              " shape: (5, 6)\n",
              " ┌───────┬────────────┬─────────────────┬─────────────────┬──────────────────┬──────────────────┐\n",
              " │ State ┆ Date       ┆ MedianSalePrice ┆ SaleToListRatio ┆ PctSoldAboveList ┆ PctSoldBelowList │\n",
              " │ ---   ┆ ---        ┆ ---             ┆ ---             ┆ ---              ┆ ---              │\n",
              " │ str   ┆ date       ┆ f32             ┆ f32             ┆ f32              ┆ f32              │\n",
              " ╞═══════╪════════════╪═════════════════╪═════════════════╪══════════════════╪══════════════════╡\n",
              " │ IA    ┆ 2010-11-13 ┆ 118500.0        ┆ null            ┆ null             ┆ null             │\n",
              " │ NH    ┆ 2023-09-09 ┆ null            ┆ null            ┆ null             ┆ null             │\n",
              " │ DE    ┆ 2015-03-14 ┆ 161137.5        ┆ null            ┆ null             ┆ null             │\n",
              " │ CT    ┆ 2011-05-07 ┆ 217625.0        ┆ null            ┆ null             ┆ null             │\n",
              " │ PA    ┆ 2018-11-03 ┆ 166150.0        ┆ 0.982659        ┆ 0.173631         ┆ 0.598239         │\n",
              " └───────┴────────────┴─────────────────┴─────────────────┴──────────────────┴──────────────────┘)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build per-dataset state-level tables and write debug outputs\n",
        "DEBUG_DIR = GOLD / 'debug'\n",
        "DEBUG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Normalize date to Date for key consistency\n",
        "to_date = pl.col('date').cast(pl.Date).alias('Date')\n",
        "\n",
        "df_sales_state = (\n",
        "    pl.scan_parquet(str(sales_path))\n",
        "    .select(\n",
        "        'State',\n",
        "        'date',\n",
        "        pl.col('Median Sale Price').alias('MedianSalePrice'),\n",
        "        pl.col('Median Sale to List Ratio').alias('SaleToListRatio'),\n",
        "        pl.col('% Sold Above List').alias('PctSoldAboveList'),\n",
        "        pl.col('% Sold Below List').alias('PctSoldBelowList'),\n",
        "    )\n",
        "    .with_columns(to_date)\n",
        "    .group_by(['State', 'Date'])\n",
        "    .agg([\n",
        "        pl.col('MedianSalePrice').median().alias('MedianSalePrice'),\n",
        "        pl.col('SaleToListRatio').median().alias('SaleToListRatio'),\n",
        "        pl.col('PctSoldAboveList').mean().alias('PctSoldAboveList'),\n",
        "        pl.col('PctSoldBelowList').mean().alias('PctSoldBelowList'),\n",
        "    ])\n",
        ").collect()\n",
        "df_sales_state.write_parquet(str(DEBUG_DIR / 'sales_state.parquet'))\n",
        "df_sales_state.shape, df_sales_state.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ac3c671f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((16012, 3),\n",
              " shape: (5, 3)\n",
              " ┌───────┬────────────┬────────────────────┐\n",
              " │ State ┆ Date       ┆ MedianListingPrice │\n",
              " │ ---   ┆ ---        ┆ ---                │\n",
              " │ str   ┆ date       ┆ f32                │\n",
              " ╞═══════╪════════════╪════════════════════╡\n",
              " │ NC    ┆ 2018-02-03 ┆ 199900.0           │\n",
              " │ LA    ┆ 2019-11-23 ┆ 198250.0           │\n",
              " │ PA    ┆ 2018-07-21 ┆ 163950.0           │\n",
              " │ WI    ┆ 2019-07-27 ┆ 219000.0           │\n",
              " │ SC    ┆ 2020-08-22 ┆ 248281.0           │\n",
              " └───────┴────────────┴────────────────────┘)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_listings_state = (\n",
        "    pl.scan_parquet(str(listings_path))\n",
        "    .select(\n",
        "        'State',\n",
        "        'date',\n",
        "        pl.col('Median Listing Price').alias('MedianListingPrice'),\n",
        "    )\n",
        "    .with_columns(to_date)\n",
        "    .group_by(['State', 'Date'])\n",
        "    .agg(pl.col('MedianListingPrice').median().alias('MedianListingPrice'))\n",
        ").collect()\n",
        "df_listings_state.write_parquet(str(DEBUG_DIR / 'listings_state.parquet'))\n",
        "df_listings_state.shape, df_listings_state.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0d81958a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((16217, 3),\n",
              " shape: (5, 3)\n",
              " ┌───────┬────────────┬──────────────┐\n",
              " │ State ┆ Date       ┆ DaysOnMarket │\n",
              " │ ---   ┆ ---        ┆ ---          │\n",
              " │ str   ┆ date       ┆ f32          │\n",
              " ╞═══════╪════════════╪══════════════╡\n",
              " │ HI    ┆ 2021-08-28 ┆ 8.0          │\n",
              " │ NE    ┆ 2023-07-08 ┆ 7.5          │\n",
              " │ NC    ┆ 2023-05-13 ┆ 5.5          │\n",
              " │ VT    ┆ 2023-09-02 ┆ null         │\n",
              " │ UT    ┆ 2022-08-20 ┆ 25.0         │\n",
              " └───────┴────────────┴──────────────┘)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dom_state = (\n",
        "    pl.scan_parquet(str(dom_path))\n",
        "    .select(\n",
        "        'State',\n",
        "        'date',\n",
        "        pl.col('Median Days on Pending').alias('DaysOnMarket'),\n",
        "    )\n",
        "    .with_columns(to_date)\n",
        "    .group_by(['State', 'Date'])\n",
        "    .agg(pl.col('DaysOnMarket').median().alias('DaysOnMarket'))\n",
        ").collect()\n",
        "df_dom_state.write_parquet(str(DEBUG_DIR / 'dom_state.parquet'))\n",
        "df_dom_state.shape, df_dom_state.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "cf6bb5df",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((12710, 9),\n",
              " shape: (5, 9)\n",
              " ┌────────────┬────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
              " │ Date       ┆ Region ┆ RegionType ┆ MedianSal ┆ … ┆ SaleToLis ┆ PctSoldAb ┆ PctSoldBe ┆ DaysOnMar │\n",
              " │ ---        ┆ ---    ┆ ---        ┆ ePrice    ┆   ┆ tRatio    ┆ oveList   ┆ lowList   ┆ ket       │\n",
              " │ date       ┆ str    ┆ str        ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
              " │            ┆        ┆            ┆ f32       ┆   ┆ f32       ┆ f32       ┆ f32       ┆ f32       │\n",
              " ╞════════════╪════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
              " │ 2018-01-06 ┆ AL     ┆ State      ┆ 185419.0  ┆ … ┆ 0.973613  ┆ 0.096774  ┆ 0.725806  ┆ 77.0      │\n",
              " │ 2018-01-06 ┆ AR     ┆ State      ┆ 152130.0  ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
              " │ 2018-01-06 ┆ AZ     ┆ State      ┆ 240100.0  ┆ … ┆ 0.980786  ┆ 0.161491  ┆ 0.668097  ┆ 41.0      │\n",
              " │ 2018-01-06 ┆ CA     ┆ State      ┆ 530500.0  ┆ … ┆ 0.996179  ┆ 0.372002  ┆ 0.478057  ┆ 32.0      │\n",
              " │ 2018-01-06 ┆ CO     ┆ State      ┆ 348750.0  ┆ … ┆ 0.998026  ┆ 0.290966  ┆ 0.478896  ┆ 27.5      │\n",
              " └────────────┴────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge the debug tables (inner join on State+Date)\n",
        "lf = (\n",
        "    df_sales_state.lazy()\n",
        "    .join(df_listings_state.lazy(), on=['State', 'Date'], how='inner')\n",
        "    .join(df_dom_state.lazy(), on=['State', 'Date'], how='inner')\n",
        "    .with_columns([\n",
        "        pl.col('State').alias('Region'),\n",
        "        pl.lit('State').alias('RegionType'),\n",
        "    ])\n",
        "    .select([\n",
        "        'Date',\n",
        "        'Region',\n",
        "        'RegionType',\n",
        "        'MedianSalePrice',\n",
        "        'MedianListingPrice',\n",
        "        'SaleToListRatio',\n",
        "        'PctSoldAboveList',\n",
        "        'PctSoldBelowList',\n",
        "        'DaysOnMarket',\n",
        "    ])\n",
        "    .sort(['Date', 'Region'])\n",
        ")\n",
        "df = lf.collect()\n",
        "df.shape, df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5e966b39",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Q1] Wrote D:\\code\\SEG\\data\\gold\\zillow\\q1_analysis.parquet with 12710 rows and 9 columns.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('D:/code/SEG/data/gold/zillow/q1_analysis.parquet', (12710, 9))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Write to gold layer\n",
        "GOLD.mkdir(parents=True, exist_ok=True)\n",
        "out_path = GOLD / 'q1_analysis.parquet'\n",
        "df.write_parquet(str(out_path))\n",
        "log(f'Wrote {out_path} with {df.height} rows and {len(df.columns)} columns.')\n",
        "out_path.as_posix(), df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "13c13ac9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Q1] Wrote D:\\code\\SEG\\data\\gold\\zillow\\demand_consistency.parquet with 41 rows and 7 columns.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((41, 7),\n",
              " shape: (5, 7)\n",
              " ┌────────┬────────────┬───────────────┬───────────────┬──────────────┬──────────────┬──────────────┐\n",
              " │ Region ┆ RegionType ┆ Avg_SaleListG ┆ Volatility_Sa ┆ Avg_PctSoldA ┆ Avg_DaysOnMa ┆ Observations │\n",
              " │ ---    ┆ ---        ┆ apPct         ┆ leListGapPct  ┆ boveList     ┆ rket         ┆ ---          │\n",
              " │ str    ┆ str        ┆ ---           ┆ ---           ┆ ---          ┆ ---          ┆ u32          │\n",
              " │        ┆            ┆ f32           ┆ f32           ┆ f32          ┆ f32          ┆              │\n",
              " ╞════════╪════════════╪═══════════════╪═══════════════╪══════════════╪══════════════╪══════════════╡\n",
              " │ AL     ┆ State      ┆ 11.125981     ┆ 11.138463     ┆ 0.318655     ┆ 13.962783    ┆ 310          │\n",
              " │ AR     ┆ State      ┆ 20.125114     ┆ 12.842976     ┆ null         ┆ 17.0         ┆ 310          │\n",
              " │ AZ     ┆ State      ┆ 1.81364       ┆ 10.011738     ┆ 0.227766     ┆ 20.396774    ┆ 310          │\n",
              " │ CA     ┆ State      ┆ 39.647392     ┆ 6.671294      ┆ 0.449603     ┆ 16.098387    ┆ 310          │\n",
              " │ CO     ┆ State      ┆ -6.478239     ┆ 4.750007      ┆ 0.413181     ┆ 12.761291    ┆ 310          │\n",
              " └────────┴────────────┴───────────────┴───────────────┴──────────────┴──────────────┴──────────────┘)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics_lf = (\n",
        "    df.lazy()\n",
        "    .with_columns(\n",
        "        (\n",
        "            (pl.col('MedianSalePrice') - pl.col('MedianListingPrice')) \n",
        "            / pl.col('MedianListingPrice') * 100\n",
        "        ).alias('SaleListGapPct')\n",
        "    )\n",
        "    .group_by('Region')\n",
        "    .agg([\n",
        "        pl.col('SaleListGapPct').std().alias('Volatility_SaleListGapPct'),\n",
        "        pl.col('SaleListGapPct').mean().alias('Avg_SaleListGapPct'),\n",
        "        pl.col('PctSoldAboveList').mean().alias('Avg_PctSoldAboveList'),\n",
        "        pl.col('DaysOnMarket').mean().alias('Avg_DaysOnMarket'),\n",
        "        pl.len().alias('Observations'),\n",
        "    ])\n",
        "    .with_columns(\n",
        "        pl.lit('State').alias('RegionType')\n",
        "    )\n",
        "    .select([\n",
        "        'Region',\n",
        "        'RegionType',\n",
        "        'Avg_SaleListGapPct',\n",
        "        'Volatility_SaleListGapPct',\n",
        "        'Avg_PctSoldAboveList',\n",
        "        'Avg_DaysOnMarket',\n",
        "        'Observations'\n",
        "    ])\n",
        "    .sort('Region')\n",
        ")\n",
        "\n",
        "metrics_df = metrics_lf.collect()\n",
        "\n",
        "# Write metrics to gold\n",
        "metrics_path = GOLD / 'demand_consistency.parquet'\n",
        "metrics_df.write_parquet(str(metrics_path))\n",
        "\n",
        "log(f'Wrote {metrics_path} with {metrics_df.height} rows and {len(metrics_df.columns)} columns.')\n",
        "\n",
        "metrics_df.shape, metrics_df.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
